# Optimized stack for sub-300ms latency
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
websockets>=12.0
aiofiles>=23.0.0

# Local translation models
torch>=2.0.0
transformers>=4.35.0
sentence-transformers>=2.2.2
accelerate>=0.24.0

# Apple Silicon optimization (if applicable)
# pip install torch torchvision torchaudio

# Existing components
qdrant-client>=1.7.0
numpy>=1.24.0
python-dotenv>=1.0.0

# Performance monitoring
psutil>=5.9.0

# Optional: GPU acceleration
# nvidia-ml-py3>=7.352.0
